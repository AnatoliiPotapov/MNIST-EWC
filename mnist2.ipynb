{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import gzip\n",
    "import pickle\n",
    "from urllib import urlretrieve\n",
    "\n",
    "def maybe_download(filename, expected_bytes, force=False):\n",
    "    \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
    "    dest_filename = os.path.join(data_root, filename)\n",
    "    if force or not os.path.exists(dest_filename):\n",
    "        print('Attempting to download:', filename) \n",
    "        filename, _ = urlretrieve(url + filename, dest_filename)\n",
    "        print('\\nDownload Complete!')\n",
    "    \n",
    "    statinfo = os.stat(dest_filename)\n",
    "    if statinfo.st_size == expected_bytes:\n",
    "        print('Found and verified', dest_filename)\n",
    "    else:\n",
    "        raise Exception(\n",
    "            'Failed to verify ' + dest_filename + '. Can you get to it with a browser?')\n",
    "    return dest_filename\n",
    "\n",
    "data_root = 'data/'\n",
    "url = 'http://deeplearning.net/data/mnist/'\n",
    "train_filename = maybe_download('mnist.pkl.gz', 16168813)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with gzip.open('data/mnist.pkl.gz', 'rb') as f:\n",
    "    (X_train, y_train), (X_val, y_val), (X_test, y_test) =  pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plot 4 images as gray scale\n",
    "plt.subplot(221)\n",
    "plt.imshow(X_train[0].reshape(28,28), cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(222)\n",
    "plt.imshow(X_train[1].reshape(28,28), cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(223)\n",
    "plt.imshow(X_train[2].reshape(28,28), cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(224)\n",
    "plt.imshow(X_train[3].reshape(28,28), cmap=plt.get_cmap('gray'))\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "image_size = 28\n",
    "num_labels = 10\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "    labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "    return dataset, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "def batch_generator(X, y, y_labels, batch_size):\n",
    "    l = X.shape[0]\n",
    "    def another():\n",
    "        indexes = np.random.randint(low=0, high=l, size=batch_size)\n",
    "        return [\n",
    "            X.take(indexes, axis=0),\n",
    "            y[indexes],\n",
    "            y_labels[indexes]\n",
    "        ]\n",
    "            \n",
    "    while True:\n",
    "        yield another()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_images(X):# plot 4 images as gray scale\n",
    "    plt.subplot(221)\n",
    "    plt.imshow(X[0].reshape(28,28), cmap=plt.get_cmap('gray'))\n",
    "    plt.subplot(222)\n",
    "    plt.imshow(X[1].reshape(28,28), cmap=plt.get_cmap('gray'))\n",
    "    plt.subplot(223)\n",
    "    plt.imshow(X[2].reshape(28,28), cmap=plt.get_cmap('gray'))\n",
    "    plt.subplot(224)\n",
    "    plt.imshow(X[3].reshape(28,28), cmap=plt.get_cmap('gray'))\n",
    "    # show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def new_batch(X, y, ids):\n",
    "    n,d = X.shape\n",
    "    indexes = np.array([False] * n)\n",
    "    for i in ids:\n",
    "        indexes = np.logical_or(indexes, y == i)\n",
    "    X = X[indexes,]\n",
    "    y_labels = y[indexes]\n",
    "    y = y[indexes]\n",
    "    X, y = reformat(X, y)\n",
    "    return([X, y, y_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "numbers = range(10)\n",
    "batches = []\n",
    "data = []\n",
    "\n",
    "\"\"\"\n",
    "for num in numbers:\n",
    "    X, y = X_train[y_train == num,], y_train[y_train == num] \n",
    "    X_neg, y_neg = X_train[y_train != num,][:10000,], y_train[y_train != num][:10000,]\n",
    "    y_labels = y_train[y_train == num]  \n",
    "    y_labels_neg = y_train[y_train != num][:10000,]  \n",
    "    X = np.concatenate((X, X_neg), axis=0)\n",
    "    y = np.concatenate((y, y_neg), axis=0)\n",
    "    y_labels = np.concatenate((y_labels, y_labels_neg), axis=0)\n",
    "    X, y = reformat(X, y)\n",
    "\n",
    "\n",
    "    data.append([X, y, y_labels])\n",
    "    batches.append(batch_generator(X, y, y_labels, batch_size=batch_size))\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "batches = []\n",
    "data = []\n",
    "\n",
    "def generate_batches(proto):\n",
    "    for ids in proto:\n",
    "        [X, y, y_labels] = new_batch(X_train, y_train, ids)\n",
    "        data.append([X, y, y_labels])\n",
    "        batches.append(batch_generator(X, y, y_labels, batch_size=batch_size))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "generate_batches([[0],[1],[2],[3],[4],[5],[6],[7],[8],[9]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "[X, y, y_labels] = new_batch(X_train, y_train, range(10))\n",
    "train_batches = batch_generator(X, y, y_labels, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X, y, y_labels = batches[0].next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plot_images(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "\n",
    "    def __init__(self, l1 = 128, l2 = 128, l1_loss = 0.0, l2_loss = 0.0, mode = 'normal', pretrained=False, ewc = 20e6):\n",
    "        \n",
    "        # Network Parameters\n",
    "        n_hidden_1 = l1 # 1st layer number of features\n",
    "        n_hidden_2 = l2 # 2nd layer number of features\n",
    "        n_input = 784 # MNIST data input (img shape: 28*28)\n",
    "        n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "        \n",
    "        # tf Graph input\n",
    "        self.tf_x = tf.placeholder(\"float\", [None, n_input])\n",
    "        self.tf_y = tf.placeholder(\"float\", [None, n_classes])\n",
    "        self.tf_labels = tf.placeholder(\"int32\", [None])\n",
    "        self.active_class = tf.placeholder(\"int32\")\n",
    "        \n",
    "        self.ewc = tf.constant(ewc)\n",
    "        self.l1_loss = tf.constant(l1_loss)\n",
    "        self.l2_loss = tf.constant(l2_loss)\n",
    "        \n",
    "        # Create model\n",
    "        def multilayer_perceptron(x, weights):\n",
    "            # Hidden layer with RELU activation\n",
    "            layer_1 = tf.matmul(x, weights['h1'])\n",
    "            layer_1 = tf.nn.relu(layer_1)\n",
    "            # Hidden layer with RELU activation\n",
    "            layer_2 = tf.matmul(layer_1, weights['h2'])\n",
    "            layer_2 = tf.nn.relu(layer_2)\n",
    "            # Output layer with linear activation\n",
    "            out_layer = tf.matmul(layer_2, weights['out'])\n",
    "            return out_layer\n",
    "        \n",
    "        self.multilayer_perceptron = multilayer_perceptron\n",
    "        \n",
    "        # Store layers weight\n",
    "        self.weights = {\n",
    "            'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "            'h1e': tf.Variable(tf.random_normal([n_input, n_hidden_1]), trainable=False),\n",
    "            'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "            'h2e': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2]), trainable=False)#,\n",
    "            #'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes])),\n",
    "            #'oute': tf.Variable(tf.random_normal([n_hidden_2, n_classes]), trainable=False)\n",
    "        }\n",
    "        \n",
    "        if pretrained == False:\n",
    "            self.weights['out'] = tf.Variable(tf.random_normal([n_hidden_2, n_classes]), name=\"vout\")\n",
    "        if pretrained == True:\n",
    "            self.weights['out'] = tf.Variable(tf.random_normal([n_hidden_2, n_classes]), trainable=False, name=\"vout\")\n",
    "\n",
    "        self.saver = tf.train.Saver({\"vout\": self.weights['out'] })\n",
    "                 \n",
    "        self.fisher = {\n",
    "            'h1': tf.Variable(tf.zeros([n_input, n_hidden_1])),\n",
    "            'h2': tf.Variable(tf.zeros([n_hidden_1, n_hidden_2]))#,\n",
    "            #'out': tf.Variable(tf.zeros([n_hidden_2, n_classes]))\n",
    "        }\n",
    "\n",
    "        # Construct model\n",
    "        self.pred = self.multilayer_perceptron(self.tf_x, self.weights)\n",
    "\n",
    "        # Define loss and optimizer\n",
    "        if mode == 'normal':\n",
    "            cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=self.pred, labels=self.tf_y)) \n",
    "        if mode == 'sparse':\n",
    "            cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=self.pred, labels=self.tf_labels))  \n",
    "        if mode == 'continuous':\n",
    "            cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "                logits=self.pred[:, 0:self.active_class+1],\n",
    "                labels=self.tf_y[:, 0:self.active_class+1]))  \n",
    "            \n",
    "        cost = cost + self.l1_loss*tf.reduce_sum(tf.abs(self.weights['h1']))\n",
    "        cost = cost + self.l1_loss*tf.reduce_sum(tf.abs(self.weights['h2']))\n",
    "        cost = cost + self.l1_loss*tf.reduce_sum(tf.abs(self.weights['h1']))\n",
    "        cost = cost + self.l2_loss*tf.nn.l2_loss(self.weights['h1'])\n",
    "        cost = cost + self.l2_loss*tf.nn.l2_loss(self.weights['h2'])\n",
    "        cost = cost + self.l2_loss*tf.nn.l2_loss(self.weights['out'])\n",
    "        self.cost = cost\n",
    "        \n",
    "        self.optimizer = tf.train.AdamOptimizer(0.01)\n",
    "        self.minimize_cost = self.optimizer.minimize(self.cost) \n",
    "        \n",
    "        self.grads = self.optimizer.compute_gradients(self.cost, [self.weights['h1'], self.weights['h2'], self.weights['out']]) \n",
    "\n",
    "        ewc_cost = self.ewc * tf.nn.l2_loss(tf.multiply(self.fisher['h1'], tf.subtract(self.weights['h1'], self.weights['h1e'])))\n",
    "        ewc_cost = ewc_cost + self.ewc * tf.nn.l2_loss(tf.multiply(self.fisher['h2'], tf.subtract(self.weights['h2'], self.weights['h2e'])))\n",
    "        #ewc_cost = ewc_cost + self.ewc * tf.nn.l2_loss(tf.multiply(self.fisher['out'], tf.subtract(self.weights['out'], self.weights['oute'])))\n",
    "        self.ewc_cost = ewc_cost\n",
    "        \n",
    "        self.objective = self.cost + self.ewc_cost\n",
    "        self.minimize_cost_ewc = self.optimizer.minimize(self.objective)\n",
    "        \n",
    "        # Initializing the variables\n",
    "        self.init = tf.global_variables_initializer()        \n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Helper functions for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "                    / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def restore(sess):\n",
    "    ckpt = tf.train.get_checkpoint_state(os.path.dirname('checkpoint_directory/{}'.format(model_name)))\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "import time\n",
    "\n",
    "class Progress(object):\n",
    "    \n",
    "    def __init__(self, max):\n",
    "        self.p = IntProgress(max = max)\n",
    "        self.p.description = 'Running'\n",
    "        self.stime = time.time()\n",
    "        self.last_delta = 0\n",
    "        self.max = max\n",
    "        display(self.p)\n",
    "    \n",
    "    def update(self, step):\n",
    "        self.p.value = step\n",
    "        delta = int(time.time() - self.stime)\n",
    "        if delta % 5 == 0 and delta > self.last_delta:\n",
    "            self.last_delta = delta\n",
    "            time_remaining = int(delta * (self.max - step) / step)\n",
    "            self.p.description = '{0}:{1}'.format(time_remaining / 60, time_remaining % 60 )                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "max_steps = 3001\n",
    "period_print = 500\n",
    "period_stat = 100\n",
    "\n",
    "def train(model, batches_list, data = None, EWC = False, stat = False, max_steps = 3001):\n",
    "    \n",
    "    acc_track = []\n",
    "    #for i in range(len(data)+1):\n",
    "    acc_track.append([])\n",
    "        \n",
    "    p = Progress(max_steps*len(batches_list))\n",
    "    pr = 0\n",
    "    \n",
    "    for ind, batches in enumerate(batches_list):\n",
    "        print(\"Training on batches{0}\\n\".format(ind+1))\n",
    "        try:\n",
    "            for step in range(max_steps):\n",
    "                \n",
    "                pr = pr+1\n",
    "                p.update(pr)\n",
    "                \n",
    "                X, y, y_labels = batches.next()\n",
    "                train_d = {model.tf_x : X, model.tf_y : y, model.tf_labels : y_labels, model.active_class : ind}\n",
    "\n",
    "                if EWC ==  False:\n",
    "                    _ = sess.run(model.minimize_cost, feed_dict=train_d)\n",
    "                if EWC ==  True:\n",
    "                    _ = sess.run(model.minimize_cost_ewc, feed_dict=train_d)\n",
    "\n",
    "                if step % period_stat == 0:\n",
    "                    #for i, d in enumerate(data):\n",
    "                    #    acc_track[i].append(test_acc(model, d[0], d[1]))\n",
    "                    \n",
    "                    X_t, y_t, y_t_labels = train_batches.next()\n",
    "                    acc_track[0].append(test_acc(model, X_t, y_t))\n",
    "\n",
    "                if (step % period_print == 0) and (stat == True):\n",
    "                    test_d = {model.tf_x : X, model.tf_y : y}\n",
    "                    l,ll, train_pred = sess.run([model.cost, model.ewc_cost, model.pred], feed_dict=test_d)\n",
    "                    print(\n",
    "                        \"Step {0}: \\n loss: {1} {2} \\n accuracy: {3}% \\n\".format(\n",
    "                            step,\n",
    "                            l,\n",
    "                            ll,\n",
    "                            test_acc(model, X_t, y_t)\n",
    "                        )\n",
    "                    )\n",
    "            set_constraint(model, X, y, y_labels, ind)\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            set_constraint(model, X, y, y_labels, ind)\n",
    "            print('training interrupted')\n",
    "\n",
    "    return acc_track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def test_acc(model, X, y):\n",
    "    #X, y = batches.next()\n",
    "    test_d = {model.tf_x : X, model.tf_y : y}\n",
    "    prediction = sess.run([model.pred], feed_dict=test_d)\n",
    "    return accuracy(prediction[0], y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_gradient(model, batches):\n",
    "    X, y = batches.next()\n",
    "    test_d = {model.tf_x : X, model.tf_y : y}\n",
    "    gradient = sess.run([model.grads], feed_dict=test_d)\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Привязать к данным\n",
    "def set_constraint(model, X, y, y_labels, id):\n",
    "    # Вычисляем Градиент по весам\n",
    "    test_d = {model.tf_x : X, model.tf_y : y, model.tf_labels : y_labels, model.active_class : id}\n",
    "    g = sess.run([model.grads], feed_dict=test_d)\n",
    "    #return gradient\n",
    "    g1, w1 = g[0][0]\n",
    "    g2, w2 = g[0][1]\n",
    "    g3, w3 = g[0][2]\n",
    "    # Забираем старые матрицы фишера\n",
    "    # Возводим в квадрат\n",
    "    with sess.as_default():\n",
    "        f1 = 0.3 * np.square(g1) + 0.7 * model.fisher['h1'].eval()\n",
    "        f2 = 0.3 * np.square(g2) + 0.7 * model.fisher['h2'].eval()\n",
    "        #f3 = 0.3 * np.square(g3) + 0.7 * model.fisher['out'].eval()\n",
    "\n",
    "    #print(np.max(f1),np.max(f2),np.max(f3))\n",
    "    with sess.as_default():\n",
    "        # Обновляем коэффициенты матрицы фишера в графе\n",
    "        model.fisher['h1'].assign(f1).eval()\n",
    "        model.fisher['h2'].assign(f2).eval()\n",
    "        #model.fisher['out'].assign(f3).eval()\n",
    "        # Обновляем центральные веса в графе\n",
    "        model.weights['h1e'].assign(w1).eval()\n",
    "        model.weights['h2e'].assign(w2).eval()\n",
    "        #model.weights['oute'].assign(w3).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def plot(acc_track, title):\n",
    "    %matplotlib inline\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.rc(\"font\", size=10)\n",
    "    fig = plt.figure()\n",
    "    fig.suptitle(title, fontsize=14)\n",
    "    axes = plt.gca()\n",
    "    axes.set_ylim([0,100])\n",
    "    l = len(acc_track[0])\n",
    "    for ind, acc in enumerate(acc_track):\n",
    "        plt.plot(range(l), acc_track[ind], label='Number {0}'.format(ind))\n",
    "    \n",
    "    plt.ylabel('accuracy, %')\n",
    "    plt.xlabel('number of training batches x100')\n",
    "    plt.legend(loc=4, borderaxespad=0.)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = Model(256, 256, l1_loss = 0.0, l2_loss = 0.0001, mode = 'normal', pretrained = False)\n",
    "#tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "sess.run(model.init)\n",
    "\n",
    "stats = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stats.append(train(model, [train_batches], data, EWC=False, stat=True, max_steps = 3001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_path = model.saver.save(sess, \"/tmp/model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(stats[0], title = \"Fig.1. (l1 = 256, l2 = 256) initial pretraining\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-41cfc6ab4e09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'normal'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mewc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#tf.reset_default_graph()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Model' is not defined"
     ]
    }
   ],
   "source": [
    "model = Model(256, 256, l1_loss = 0.0, l2_loss = 0.0, mode = 'normal', pretrained = True, ewc = 1e15)\n",
    "#tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "sess.run(model.init)\n",
    "\n",
    "stats = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.saver.restore(sess, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stats.append(train(model, b, data, EWC=True, stat=True, max_steps = 501))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "b = []\n",
    "\n",
    "for i in range(10):\n",
    "    for j in range(2*i):\n",
    "        b.append(batches[np.random.randint(low = 0, high = i+1, size=1, dtype='l')[0]\n",
    "])\n",
    "        \n",
    "len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "stats.append(train(model, b, data, EWC=False, stat=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plot(stats[0], title = \"Fig.3. (l1 = 64, l2 = 256) with EWC \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "b = []\n",
    "\n",
    "for i in range(10):\n",
    "    for j in range(2*i):\n",
    "        b.append(batches[np.random.randint(low = 0, high = i+1, size=1, dtype='l')[0]\n",
    "])\n",
    "        \n",
    "len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = Model(1024, 128, l1_loss = 0.0, l2_loss = 0.0001, mode = 'normal')\n",
    "sess.run(model.init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "stats.append(train(model, b, data, EWC=True, stat=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plot(stats[1], title = \"Fig.3. (l1 = 64, l2 = 256) with EWC \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {
    "2ccdd97d304f4200b0814d8b92efd00e": {
     "views": [
      {
       "cell_index": 28
      }
     ]
    },
    "530cf050973e4750a6592f37047553e2": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    },
    "73ad6de3a38b400a91495819e07ce4b9": {
     "views": [
      {
       "cell_index": 33
      }
     ]
    },
    "74264b07ec9841d5ad18ecfc34e0871a": {
     "views": [
      {
       "cell_index": 32
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
